{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tI140e3BMOS3",
        "mdNbRVpujRHX",
        "zveJEd_V5hbP",
        "nF8MmzrPPQjb"
      ],
      "mount_file_id": "1RQIozOJ5cERbXqnoWI_zRfNPQ6PMTl8i",
      "authorship_tag": "ABX9TyOXetpgpx4YeQ4TxAtPNeN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaelinN/VAE_RECOMMENDER_IMPLICIT_FEEDBACK/blob/main/Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVqZqv6MJax"
      },
      "source": [
        "#imports and dirs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWM4mbkFmfM-"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy import sparse\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukpLpazmmtlG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, activations, Model, losses, metrics\n",
        "import math\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "import tensorflow.keras.backend as tfback\n",
        "\n",
        "import argparse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLFEkTjv3BQf"
      },
      "source": [
        "'''\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--root', type=str, default=rt)\n",
        "parser.add_argument('--input_data', type=str, default=inp)\n",
        "parser.add_argument('--output_results', type=str, default=outp)\n",
        "parser.add_argument('--vae_weight_file', type=str)\n",
        "parser.add_argument('--svdpp_file', type=str)\n",
        "\n",
        "parser.add_argument('--u_lookup', type=str)\n",
        "parser.add_argument('--b_lookup', type=str)\n",
        "\n",
        "parser.add_argument('--prev_cutoff_prediction', type=int)\n",
        "\n",
        "parser.add_argument('--prediction_temp_file_vae', type=str)\n",
        "parser.add_argument('--prediction_temp_file_svd', type=str)\n",
        "\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "'''\n",
        "class argclass(object):\n",
        "  def __init__(self):\n",
        "    self.root = \"/content/drive/MyDrive/COMP700_Honours Project\"\n",
        "    self.input_data = \"Data/remove_low_interaction_users/matrices/implicit\"\n",
        "    self.output_results =\"results\"\n",
        "    self.vae_weight_file = \"models/vae_epoch_01_loss_210.97.hdf5\"\n",
        "    self.svdpp_file = \"svdpp_model.pkl\"\n",
        "    self.u_lookup = \"Data/remove_low_interaction_users/unique_u.txt\"\n",
        "    self.b_lookup = \"Data/remove_low_interaction_users/unique_b.txt\"\n",
        "\n",
        "    self.prev_cutoff_prediction = 0\n",
        "\n",
        "    self.prediction_temp_file_vae = \"vae_pred_temp.csv\"\n",
        "    self.prediction_temp_file_svd = \"svd_pred_temp.csv\"\n",
        "\n",
        "\n",
        "args = argclass()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5goBSM5_4biF"
      },
      "source": [
        "root = args.root #\"/content/drive/MyDrive/COMP700_Honours Project\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXX8Ci5WeO-u"
      },
      "source": [
        "input_data  = os.path.join(root, args.input_data)\n",
        "\n",
        "vae_weights = os.path.join(root, args.vae_weight_file)\n",
        "svdpp_model = os.path.join(root, args.svdpp_file)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxMtrxfZOFDD"
      },
      "source": [
        "output_results = os.path.join(root, args.output_results)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9WzAiJ4N13h"
      },
      "source": [
        "try:\n",
        "  os.mkdir(output_results)\n",
        "except FileExistsError:\n",
        "  pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTVHgs8jMiUO"
      },
      "source": [
        "#Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaGcJwPLX5a"
      },
      "source": [
        "#convert a DF of results into a sparse matrix. allows for easier reuse of code\n",
        "def results_mat_from_df(results, u_lookup, b_lookup):\n",
        "  num_u = len(u_lookup)  \n",
        "  num_b = len(b_lookup) \n",
        "\n",
        "  #u_map = {strid:intidx for intidx, strid in enumerate(u_lookup)}\n",
        "  #b_map = {strid:intidx for intidx, strid in enumerate(b_lookup)}\n",
        "\n",
        "  rows = results['uid'] #[ u_map[uid] for uid in results['uid'] ] \n",
        "  cols = results['bid']#[ b_map[bid] for bid in results['bid'] ] \n",
        "\n",
        "  values = results['rate']\n",
        "\n",
        "  sparse_pred = sparse.csr_matrix(  (values , (rows, cols)) , shape=( num_u,num_b) )\n",
        "\n",
        "  return sparse_pred"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EjS_JX6cLvN"
      },
      "source": [
        "def predictions_to_csv(test_mat, u_lookup, b_lookup, model, model_type = \"SVDpp\"):\n",
        "  columns=['uid','bid', 'rate']\n",
        "  results = []\n",
        "\n",
        "  prev_cutoff = args.prev_cutoff_prediction if args.prev_cutoff_prediction is not None else 0\n",
        "  for user in range(prev_cutoff, test_mat.shape[0]):\n",
        "    #uid = u_lookup[user]\n",
        "    test_vec  = np.array(test_mat[user].todense())\n",
        "\n",
        "    if model_type == \"SVDpp\":\n",
        "      test_pred = svdpp_predictions(model, user, u_lookup, b_lookup, test_vec)\n",
        "    elif model_type ==\"VAE\":\n",
        "      test_pred = vae_predictions(model, test_vec)\n",
        "\n",
        "    for business in range(test_vec.shape[1]):\n",
        "      #bid = b_lookup[business]\n",
        "      result_rate = test_pred[business]\n",
        "      if result_rate != 0:\n",
        "        results.append([user, business, result_rate])\n",
        "\n",
        "\n",
        "    if not user%100:\n",
        "      print(user)\n",
        "    if not user%1000:\n",
        "      results = pd.DataFrame(results, columns = columns)\n",
        "      temp_dir = args.prediction_temp_file_vae if model_type==\"VAE\" else args.prediction_temp_file_svd if model_type==\"SVDpp\" else \"temp_preds.csv\"\n",
        "      is_new_file = user==0\n",
        "      results.to_csv(temp_dir,\n",
        "                     index=False, \n",
        "                     header=is_new_file, \n",
        "                     mode= \"w\" if is_new_file else \"a\"\n",
        "                     )\n",
        "      results = []\n",
        "\n",
        "  results = pd.DataFrame(results, columns = columns)\n",
        "  results.to_csv(temp_dir,\n",
        "                index=False, \n",
        "                header=False, \n",
        "                mode=\"a\"\n",
        "                )\n",
        "\n",
        "def csv_preds_to_sparse(file, u_lookup, b_lookup):\n",
        "  results = pd.read_csv(file)\n",
        "  results_mat = results_mat_from_df(results, u_lookup, b_lookup)\n",
        "  resuls_df = None\n",
        "  return results_mat"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmed-uQxBXfW"
      },
      "source": [
        "def svdpp_predictions(svdpp_machine, user, u_lookup, b_lookup, test_vec):\n",
        "  uid = u_lookup[user]\n",
        "  bids = [ b_lookup[business]  for business in range(test_vec.shape[1])]\n",
        "  test_pred = []\n",
        "  for bid in bids:\n",
        "    test_pred.append(test_pred.append(svdpp_machine.predict(uid, bid))[\"est\"])\n",
        "  return test_pred"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6f9EFjgJ6p4"
      },
      "source": [
        "def vae_predictions(vae_machine, test_vec):\n",
        "  test_pred = vae_machine.predict(test_vec)\n",
        "  test_pred = test_pred[0]  \n",
        "  return test_pred\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI140e3BMOS3"
      },
      "source": [
        "#Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFmYcWyKyPjJ"
      },
      "source": [
        "# recall for one user vector only\n",
        "def sub_value_recall_at_k(vec_true , vec_pred, k):\n",
        "  #check if there are really items this user enjoyed\n",
        "  top_rated = np.argwhere(vec_true)\n",
        "  if len(top_rated) ==0:\n",
        "    return\n",
        "  \n",
        "  top_predicted = sorted(range(len(vec_pred)), key=lambda i: vec_pred[i]) [-k:]\n",
        "  \n",
        "  sum = 0.0\n",
        "  for i in range(0, k):\n",
        "    if top_predicted[i] in top_rated:\n",
        "      sum+=1.0\n",
        "  recall = sum/float(min(k, len(top_rated)))\n",
        "\n",
        "  return recall"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH7bRkzr3tZA"
      },
      "source": [
        "# ndcg for one user vector only\n",
        "def sub_value_ndcg(vec_true, vec_pred, k):\n",
        "  top_rated = np.argwhere(vec_true)\n",
        "  if len(top_rated) ==0:\n",
        "    return\n",
        "  top_predicted = sorted(range(len(vec_pred)), key=lambda i: vec_pred[i])[-k:]\n",
        "  sum_ndcg = 0\n",
        "  for i in range(0, k):\n",
        "    if top_predicted[i] in top_rated:\n",
        "      ndcg = 1/(math.log(i+2))\n",
        "    else:\n",
        "      ndcg = 0\n",
        "    sum_ndcg += ndcg\n",
        "  return sum_ndcg "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQjaYuNom26k"
      },
      "source": [
        "#avg recalls and ndcg over entire user set\n",
        "def evaluate(full_true_mat, test_preds_mat, u_lookup, b_lookup):\n",
        "  recall20 = []\n",
        "  recall50 = []\n",
        "  ndcg20 = []\n",
        "\n",
        "  for user in range(full_true_mat.shape[0]):\n",
        "    uid = u_lookup[user]\n",
        "\n",
        "    test_true = np.array(full_true_mat[user].todense())\n",
        "    test_pred = np.array(test_preds_mat[user].todense())\n",
        "\n",
        "    recall20.append(sub_value_recall_at_k(test_true, test_pred, 20))\n",
        "    recall50.append(sub_value_recall_at_k(test_true, test_pred, 50))\n",
        "    ndcg20.append(sub_value_ndcg(test_true, test_pred, 20))\n",
        "\n",
        "  recall20 = np.array(recall20)\n",
        "  recall20_avg = np.sum(recall20) / float(len(recall20))\n",
        "\n",
        "  recall50 = np.array(recall50)\n",
        "  recall50_avg = np.sum(recall50) / float(len(recall50))\n",
        "\n",
        "  ndcg20 = np.array(ndcg20)\n",
        "  ndcg20 = ndcg20 / ndcg20.max()  #NORMALISATION\n",
        "  ndcg20_avg = np.sum(ndcg20) / float(len(ndcg20))\n",
        "\n",
        "  return recall20_avg , recall50_avg , ndcg20_avg"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_jMEM8HNBt1"
      },
      "source": [
        "#ACTUAL RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdNbRVpujRHX"
      },
      "source": [
        "##set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkdpykFWqWOx"
      },
      "source": [
        "full_true = pickle.load(open(os.path.join(input_data,\"impl_all.pkl\"), \"rb\"))\n",
        "test = pickle.load(open(os.path.join(input_data,\"impl_test.pkl\"), \"rb\"))\n",
        "\n",
        "with open(os.path.join(root, args.b_lookup) , 'r', encoding='utf-8') as bfile:\n",
        "  unique_b = bfile.readlines()\n",
        "  idx_to_b = [b.strip() for b in unique_b]\n",
        "\n",
        "with open(os.path.join(root, args.u_lookup) , 'r', encoding='utf-8') as ufile:\n",
        "  unique_u = ufile.readlines()\n",
        "  idx_to_u = [u.strip() for u in unique_u]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WaK9aq4PK3i"
      },
      "source": [
        "##Get predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zveJEd_V5hbP"
      },
      "source": [
        "###SVD++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfqNP6MbrsDP"
      },
      "source": [
        "#svdpp = pickle.load(svdpp_model) # get the trained svdpp from where it is stored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX3Doi2OuKqo"
      },
      "source": [
        "#predictions_to_csv(test, idx_to_u, idx_to_b, svdpp, \"SVDpp\")\n",
        "#svdpp_results = csv_preds_to_sparse(args.prediction_temp_file_svd , idx_to_u, idx_to_b)\n",
        "\n",
        "#pickle.dump(svdpp_results, open(os.path.join(output_results,\"svd_preds.pkl\"), \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuEQT4cu5j0D"
      },
      "source": [
        "###VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARLoHqd5sDb"
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "  def __init__(self, name=\"Sampling\", **kwargs):\n",
        "    super(Sampling, self).__init__(name=name, **kwargs)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "\n",
        "\n",
        "    #epsilon = distribution.sample()\n",
        "    \n",
        "    epsilon = tfback.random_normal(shape=(batch,dim))\n",
        "    sample = epsilon * tf.exp(0.5 * z_log_var)  +   z_mean  #Reparametrization trick: convert from standard normal to desired distribution\n",
        "\n",
        "    return sample"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QozTQD_45sKJ"
      },
      "source": [
        "#NOTE: NO ANNEALLING FOR TESTING\n",
        "\n",
        "KLBeta = 1\n",
        "def VAE_loss(y_true, y_pred):\n",
        "    global KLBeta\n",
        "    reconst_loss =  original_dim * losses.binary_crossentropy(y_true, y_pred)\n",
        "    KLDiv = KLBeta * losses.kl_divergence(y_true, y_pred)\n",
        "\n",
        "    return  reconst_loss + KLDiv"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuYdczlq9oXN"
      },
      "source": [
        "original_dim = 127350 #test.shape[1]\n",
        "intermediate_dim =  512\n",
        "latent_dim = intermediate_dim//2 "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S90yJ8N5ndk"
      },
      "source": [
        "class vae_builder(object):\n",
        "  def __init__(self, original_dim, intermediate_dim, latent_dim, name='VAE'):\n",
        "    self.name = name\n",
        "    self.original_dim = original_dim\n",
        "    self.intermediate_dim = intermediate_dim\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  \n",
        "  def build(self):\n",
        "    self.input = layers.Input(self.original_dim, name = 'input')\n",
        "    self.dropout = layers.Dropout(rate=0.5)(self.input)\n",
        "\n",
        "    #encoder\n",
        "    self.e1 = layers.Dense(self.intermediate_dim, activation=activations.hard_sigmoid, name = 'e1')(self.dropout)\n",
        "    self.e2 = layers.Dense(self.intermediate_dim, activation=activations.hard_sigmoid, name = 'e2')(self.e1)\n",
        "    self.e3 = layers.Dense(self.intermediate_dim, activation=activations.hard_sigmoid, name = 'e3')(self.e2)\n",
        "    self.e4 = layers.Dense(self.intermediate_dim, activation=activations.hard_sigmoid, name = 'e4')(self.e3)\n",
        "    self.e5 = layers.Dense(self.intermediate_dim, activation=activations.hard_sigmoid, name = 'e5')(self.e4)\n",
        "\n",
        "    #sampling\n",
        "    self.mean = layers.Dense(self.latent_dim, name = 'mean')(self.e5)  \n",
        "    self.log_var = layers.Dense(self.latent_dim, name = 'log_var')(self.e5)  \n",
        "    self.sampling = Sampling()([self.mean, self.log_var])\n",
        "\n",
        "    #decoder\n",
        "    self.d1 = layers.Dense(self.intermediate_dim, activation='relu',name = 'd1')(self.sampling)\n",
        "    self.d2 = layers.Dense(self.original_dim, activation='relu', name = 'd2')(self.d1)  \n",
        "    \n",
        "    self.output = layers.Activation(activations.swish, name = 'output')(self.d2)\n",
        "\n",
        "    #to model\n",
        "    vae = Model(inputs = self.input, outputs = self.output, name = self.name)\n",
        "    return vae"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD5g3ta7OiUm"
      },
      "source": [
        "#BUILD STRUCTURE\n",
        "v = vae_builder(original_dim, intermediate_dim, latent_dim).build()\n",
        "\n",
        "#configurable optimiser\n",
        "slow_adam = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "v.compile(optimizer=slow_adam, loss=VAE_loss)\n",
        "\n",
        "v.load_weights(vae_weights)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "mZ4dfbHpNglE",
        "outputId": "fc162020-aea7-469f-b261-ee71fadd70c5"
      },
      "source": [
        "predictions_to_csv(test, idx_to_u, idx_to_b, v, \"VAE\")\n",
        "vae_results = csv_preds_to_sparse(args.prediction_temp_file_vae , idx_to_u, idx_to_b)\n",
        "\n",
        "pickle.dump(vae_results, open(os.path.join(output_results,\"vae_preds.pkl\"), \"wb\"))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-181ccb5ca9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VAE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvae_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_preds_to_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_temp_file_vae\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0midx_to_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"vae_preds.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-981a84eeaad6>\u001b[0m in \u001b[0;36mpredictions_to_csv\u001b[0;34m(test_mat, u_lookup, b_lookup, model, model_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbusiness\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m#bid = b_lookup[business]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mresult_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult_rate\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF8MmzrPPQjb"
      },
      "source": [
        "##Evaluate predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1y_N-5dPfDp"
      },
      "source": [
        "#svdpp_results = pickle.load( open(os.path.join(output_results,\"svd_preds.pkl\"), \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhU9ejYmPSxg"
      },
      "source": [
        "#vae_results = pickle.load(open(os.path.join(output_results,\"vae_preds.pkl\"), \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxhrWfpEP1Gp"
      },
      "source": [
        "#vae_metrics = evaluate(full_true, vae_results, idx_to_u, idx_to_b)\n",
        "#vae_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CxDnmaFQLDR"
      },
      "source": [
        "#svdpp_metrics = evaluate(full_true, svdpp_results, idx_to_u, idx_to_b)\n",
        "#svdpp_metrics"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}